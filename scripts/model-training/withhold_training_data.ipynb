{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import xarray as xr\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Symmetric Log Transformation\n",
    "def symmetric_log(x, C):\n",
    "    return np.sign(x) * np.log1p(np.abs(x) + C)\n",
    "\n",
    "# Inverse of the symmetric log\n",
    "def inverse_symmetric_log(y, C):\n",
    "    return np.sign(y) * (np.exp(np.sign(y) * y) - C - 1)\n",
    "\n",
    "class MappableDataset(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.target[idx], dtype=torch.float32)\n",
    "\n",
    "class EKE_Dataset(MappableDataset):\n",
    "    def __init__(self, file_path, do_normalization=True):\n",
    "        self.do_normalization = do_normalization\n",
    "\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        # TODO: Check to see if we should be dynamically changing this\n",
    "        self.C = self._compute_C(ds.RV_vert_avg.values.flatten())\n",
    "\n",
    "        vars = [\"KE_vert_sum\", \"RV_vert_avg\", \"slope_vert_avg\", \"Rd_dx_scaled\"]\n",
    "        # Extract features & target, flattening them to 1D vectors\n",
    "        features = np.stack(\n",
    "            [ds[var].values.flatten() for var in vars],\n",
    "            axis=1\n",
    "        )\n",
    "        target = np.log1p(ds['EKE'].values.flatten())  # Log transform target\n",
    "\n",
    "        # **Filter out samples where ln(EKE) < 0**\n",
    "        valid_indices = target > 0\n",
    "        super().__init__(features[valid_indices,:], target[valid_indices])\n",
    "\n",
    "        # Compute mean & std for standardization (across dataset)\n",
    "        self.mean = self.features.mean(axis=0)\n",
    "        self.std = self.features.std(axis=0)\n",
    "        self.features = self.transform(self.features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def normalize(self, X):\n",
    "        return (X - self.mean)/self.std\n",
    "\n",
    "    def inverse_normalize(self, X):\n",
    "        return X*self.std + self.mean\n",
    "\n",
    "    def transform(self, X):\n",
    "        Y = np.zeros_like(X)\n",
    "        Y[:,0] = np.log1p(X[:,0])\n",
    "        Y[:,1] = symmetric_log(X[:,1], self.C)  # Symmetric Log\n",
    "        Y[:,2] = np.log1p(X[:,2])\n",
    "        Y[:,3] = X[:,3]\n",
    "\n",
    "        if self.do_normalization:\n",
    "            Y = self.normalize(Y)\n",
    "        return Y\n",
    "\n",
    "    # Undo the transform\n",
    "    def inverse_transform(self, X):\n",
    "        if self.do_normalization:\n",
    "            Y = self.inverse_normalize(X)\n",
    "        else:\n",
    "            Y = X.copy()\n",
    "\n",
    "        Y[:,0] = np.expm1(Y[:,0])\n",
    "        Y[:,1] = inverse_symmetric_log(Y[:,1], self.C)\n",
    "        Y[:,2] = np.expm1(Y[:,2])\n",
    "        return Y\n",
    "\n",
    "    # Function to compute C dynamically based on the smallest nonzero absolute value in RV_vert_avg\n",
    "    def _compute_C(self, RV):\n",
    "        nonzero_values = np.abs(RV[RV != 0])\n",
    "        C = np.min(nonzero_values) if len(nonzero_values) > 0 else 1.0  # Avoid zero\n",
    "        return np.log(C + 1)\n",
    "\n",
    "    # Return a truncated dataset by deliberating excluding a cluster of data\n",
    "    # Default is the most positive relative vorticity\n",
    "    def truncate(self, feature_idx=1):\n",
    "        clusters = KMeans(n_clusters=6, random_state=0).fit(self.features)\n",
    "        centers_dimensional = self.inverse_transform(clusters.cluster_centers_)\n",
    "        print(centers_dimensional)\n",
    "        excluded_cluster = np.argmax(centers_dimensional[:,feature_idx])\n",
    "        retained_idx = clusters.labels_ != excluded_cluster\n",
    "        truncated = MappableDataset(self.features[retained_idx], self.target[retained_idx])\n",
    "        truncated.clusters = clusters\n",
    "        truncated.excluded_cluster = excluded_cluster\n",
    "        return truncated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = pathlib.Path(\"/lustre/data/shao/cug_2024/\")\n",
    "SIMULATION_DATA = DATAPATH / \"featurized.nc\"\n",
    "TRAINING_DATA = DATAPATH / \"training_data.pkl\"\n",
    "OUTPUT_CLUSTER = DATAPATH / \"clusters.pkl\"\n",
    "ds = EKE_Dataset(SIMULATION_DATA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.44920196e+02  1.15463336e-02  3.57502202e-03  5.74257489e-01]\n",
      " [ 1.53860461e+02 -1.03021710e-03  2.16386084e-03  6.80731294e-01]\n",
      " [ 9.14740434e+00 -6.29118175e-04  4.45399527e-04  7.76396870e-01]\n",
      " [ 1.12734897e+01 -3.85966267e-04  1.16298642e-03  3.68724724e-01]\n",
      " [ 2.48926633e+02 -1.68839914e-03  3.68238037e-03  5.26326932e-01]\n",
      " [ 2.03785435e+02 -1.28160361e-02  2.97113680e-03  5.63655733e-01]]\n"
     ]
    }
   ],
   "source": [
    "truncated_ds = ds.truncate()\n",
    "with open(TRAINING_DATA, \"wb\") as f:\n",
    "  pickle.dump(truncated_ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(excluded_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in excluded cluster: 0\n"
     ]
    }
   ],
   "source": [
    "labels = clusters.predict(truncated_ds.features)\n",
    "print(f\"Samples in excluded cluster: {np.sum(labels == excluded_cluster)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in excluded cluster: 846338\n",
      "Total number of samples: 8821872\n"
     ]
    }
   ],
   "source": [
    "labels = clusters.predict(ds.features)\n",
    "print(f\"Samples in excluded cluster: {np.sum(labels == excluded_cluster)}\")\n",
    "print(f\"Total number of samples: {ds.features.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_CLUSTER, \"wb\") as f:\n",
    "  pickle.dump(clusters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in excluded cluster: 0\n",
      "Samples in excluded cluster: 846338\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_CLUSTER, \"rb\") as f:\n",
    "  clusters_test = pickle.load(f)\n",
    "labels = clusters_test.predict(truncated_ds.features)\n",
    "print(f\"Samples in excluded cluster: {np.sum(labels == excluded_cluster)}\")\n",
    "labels = clusters.predict(ds.features)\n",
    "print(f\"Samples in excluded cluster: {np.sum(labels == excluded_cluster)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cug-env-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
